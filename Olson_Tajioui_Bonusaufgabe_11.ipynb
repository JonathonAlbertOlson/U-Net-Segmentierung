{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceaa7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonathon\\Desktop\\Vertiefung KI & ML\\Abgaben\\Abgabe 8\\pytorch-unet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-unet'...\n",
      "c:\\Users\\Jonathon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"pytorch_unet.py\"):\n",
    "  if not os.path.exists(\"pytorch_unet\"):\n",
    "    !git clone https://github.com/usuyama/pytorch-unet.git\n",
    "\n",
    "  %cd pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check torch\n",
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
    "\n",
    "print(\"device name\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da35bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "input_images, target_masks = simulation.generate_random_data(128, 128, count=64)\n",
    "\n",
    "print(\"input_images shape and range\", input_images.shape, input_images.min(), input_images.max())\n",
    "print(\"target_masks shape and range\", target_masks.shape, target_masks.min(), target_masks.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_side_by_side([input_images_rgb[:3], target_masks_rgb[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "  def __init__(self, count, transform=None):\n",
    "    self.input_images, self.target_masks = simulation.generate_random_data(128, 128, count=count)\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = self.input_images[idx]\n",
    "    mask = self.target_masks[idx]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return [image, mask]\n",
    "\n",
    "# use the same transformations for train/val in this example\n",
    "trans = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.4, 0.5, 0.6], [0.20, 0.21, 0.22]) # skew channels of binary images\n",
    "])\n",
    "\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "  'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "  'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "  'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "  inp = inp.numpy().transpose((1, 2, 0))\n",
    "  mean = np.array([0.4, 0.5, 0.6])\n",
    "  std = np.array([0.20, 0.21, 0.22])\n",
    "  inp = std * inp + mean\n",
    "  inp = np.clip(inp, 0, 1)\n",
    "  inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "  return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define unet\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "      #to be completed\n",
    "        conv1 = self.dconv_down1(x)\n",
    "\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "      \n",
    "model = UNet(6).cuda() #6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac51a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        epoch_samples = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = F.binary_cross_entropy_with_logits(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            epoch_samples += inputs.size(0)\n",
    "\n",
    "        print(f\"{(loss.detach().cpu().numpy(), epoch_samples, phase)}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "model.eval()   # Set model to the evaluation mode\n",
    "\n",
    "# Create a new simulation dataset for testing\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "# Get the first batch\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.cuda()\n",
    "labels = labels.cuda()\n",
    "print('inputs.shape', inputs.shape)\n",
    "print('labels.shape', labels.shape)\n",
    "\n",
    "# Predict\n",
    "pred = model(inputs)\n",
    "# The loss functions include the sigmoid function.\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print('pred.shape', pred.shape)\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
